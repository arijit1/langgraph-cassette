# ğŸï¸ LangGraph Cassette

> Record once. Replay forever.  
> Build and debug LangGraph / LangChain agents **without burning tokens**.

---

## ğŸš€ Why

Calling real LLMs for every test or iteration is **slow** and **expensive**.  
**LangGraph Cassette** lets you:

- Record real API responses once
- Re-run them offline, deterministically
- Inspect token usage and costs per call

---

## âœ¨ Features

- ğŸ”„ **Record â†’ Replay** OpenAI (or any LangChain model) calls
- ğŸ’¾ **JSON cassettes** for easy diffing and version control
- ğŸ’° **Token & Cost logger**
- ğŸ§© **Mock LLM** for offline prototyping
- âš™ï¸ **Modes:** `live`, `record`, `replay`, `auto`
- ğŸª„ **LangGraph-first ergonomics**

---

## ğŸ“¦ Installation

npm install langgraph-cassette

### Example
## Record Once

CASSETTE_MODE=record CASSETTE_DIR=.cassettes \
node examples/langgraph.mjs

## Replay offline

CASSETTE_MODE=replay CASSETTE_DIR=.cassettes node examples/langgraph.mjs


## TERMINAL COMMANDS

CASSETTE_MODE=record CASSETTE_DIR=.cassettes node examples/langchain.mjs
# or
CASSETTE_MODE=replay CASSETTE_DIR=.cassettes node examples/langchain.mjs
# or
CASSETTE_REPLAY_MISS=mock CASSETTE_MODE=replay node examples/langchain.mjs
# or
CASSETTE_REPLAY_MISS=live CASSETTE_MODE=replay node examples/langchain.mjs
# or
CASSETTE_MODE=record CASSETTE_DIR=.cassettes node examples/langgraph.mjs